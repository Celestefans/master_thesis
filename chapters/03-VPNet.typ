#import "@preview/modern-ecnu-thesis:0.3.0": documentclass, indent, no-indent, word-count-cjk, total-words, bilingual-figure





= 面向一体化任务的视觉感知与动态路由GISR方法

== 引言
引导图像超分辨率（Guided Image Super-Resolution, GISR）旨在利用高分辨率的辅助模态图像（如全色图像、RGB图像等）来指导低分辨率目标图像的重建，在遥感对地观测、医学影像分析以及三维深度估计等领域发挥着至关重要的作用。
随着深度学习技术的发展，针对单一特定任务（如全色锐化、磁共振图像超分或深度图超分）的专用模型已经取得了显著的性能提升。然而，在实际应用场景中，往往需要处理来自不同传感器、不同模态以及不同放大倍率的多源数据。如图 @fig:first (a) 所示，传统的“一任务一模型”范式不仅导致了巨大的存储与计算开销，也难以挖掘不同GISR子任务之间潜在的共性特征。因此，如图 @fig:first (b) 所示，构建一个能够同时处理多种GISR任务的一体化（All-in-One）模型，已成为当前图像复原领域的重要研究趋势。

#figure(
  caption: [One-by-One 单任务模型与 All-in-One 一体化多任务模型的范式对比],
)[
#image("../images/实验图片/第三章/first.png", width: 100%)
] <first>

尽管一体化模型具有极高的应用价值，但其训练过程面临着严峻的挑战。与去噪、去雨等自然图像复原任务不同，GISR涵盖了全色影像、深度图和磁共振影像等多种差异巨大的数据模态。这些模态在成像机理、频谱特性以及纹理结构上存在显著的分布差异（Domain Gap）。如果简单地将所有任务的数据混合，强制使用一个共享参数的骨干网络（Shared Backbone）进行训练，不同任务的梯度更新方向往往会发生冲突，导致模型参数在优化过程中产生震荡。这种现象被称为“任务干扰”或“负迁移”，不同任务的优化方向不同，导致一体化模型在某些子任务上的性能反而低于单独训练的专用模型。

在设计一体化网络之前，我们需要先深入理解不同GISR子任务在特征空间中的分布特性。为了探究多任务混合训练时潜在的干扰机制，我们对一个本章方法所使用的基础Encoder-Decoder网络模型Restormer，在处理不同任务时的中间特征进行了统计分析。

@fig:L2 展示了不同任务在编码-解码架构中某些通道的$L_2$ 范数分布情况。从图中可以清晰地观察到，不同任务（如全色锐化、磁共振超分）在同一通道上的激活强度存在显著差异。例如，在第8通道，全色锐化任务表现出极高的激活值，而深度图超分任务的激活值则接近于零。


#figure(
  caption: [使用编码器-解码器网络架构处理不同的 GISR 子任务时，某些通道的特征图的 L2 范数分布],
)[
#image("../images/TNNLS/channel_feature.png", width: 100%)
] <L2>

为了解决上述“任务干扰”问题，打破多任务协同训练的瓶颈，并充分利用高分辨率引导图片的指导能力，本章提出了一种面向一体化任务的视觉感知与动态路由GISR方法（VPNet）。该方法摒弃了传统静态网络的参数共享机制，引入了混合专家（Mixture-of-Experts, MoE）架构思想，旨在通过网络结构的动态化来实现特征的物理解耦。
具体而言，我们设计了一个视觉感知路由模块（Visual-Perception Routing Module, VPRM），该模块能够充当“交通指挥员”的角色。它利用输入图像自身的底层视觉特征（如纹理、边缘、灰度分布等），以及引导图片中提取的视觉特征，共同作为隐式的感知信号，为每个像素动态分配最匹配的专家网络（Experts）路径。

通过这种基于视觉感知的动态路由机制，模型能够根据输入数据的模态特性，自适应地激活特定的计算分支。例如，全色锐化任务倾向于激活处理高频细节的专家，而深度图超分任务则可能更多地依赖处理平滑梯度的专家。这种机制在不显著增加计算量的前提下，有效地隔离了不同任务间的特征干扰，使得模型既能保留对共性特征的学习能力，又能兼顾不同模态的特异性需求。本章将详细阐述该方法的网络架构设计、动态路由机制的实现细节，并通过一系列实验验证其在一体化GISR任务中的有效性。




== 方法

本章的研究重点在于利用底层视觉特征引导一体化模型高效处理多模态任务，从而缓解不同GISR子任务间的参数干扰问题。为实现该目标，提出了一种面向一体化任务的视觉感知与动态路由GISR方法（VP-Net），其整体架构如图3.1所示。该方法摒弃了传统的静态共享参数模式，通过引入视觉感知路由机制，根据输入图像的纹理和结构特性动态规划特征提取路径，实现任务特征的物理解耦。本章将在@VPnet-overall-arch 节首先阐述模型的整体网络架构；随后在@VPNet-VPRM 节详细介绍核心组件——基于视觉感知的动态路由模块的设计细节与工作机理；最后在@VPNet-Loss 节给出用于指导模型优化的损失函数定义。


=== 整体网络架构 <VPnet-overall-arch>

#figure(
  caption: [VPNet网络整体架构],
)[
#image("../images/model_3.png", width: 100%)
] <VPNet-Arch>

如@fig:VPNet-Arch 所示，本章提出的 VP-Net 建立在一个分层的 U 型编码器-解码器（Encoder-Decoder）架构之上。该骨干网络设计灵感来源于 Restormer ，旨在利用其高效的 Transformer 模块处理高分辨率特征，并通过多尺度的特征交互来捕捉图像的长距离依赖与局部细节。VP-Net 主要由三个部分组成：浅层特征提取模块、嵌入视觉感知路由的编码器、以及图像重建解码器。

模型的输入包含两个部分：待恢复的低分辨率目标图像$I_"LR" in RR^(H times W times C_"in")$ 和高分辨率引导图像 $I_"HR" in RR^("sH" times "sW" times C_"guide")$（其中 $s$ 为超分倍率）。

由于 $I_"LR"$ 和 $I_"HR"$ 来自不同的模态（如全色、深度或磁共振），且具有不同的空间分辨率，我们首先使用两个独立的 $3 times 3$ 卷积层作为浅层特征提取器，分别将它们映射到统一的通道维度 $C$。
对于 $I_"LR"$，提取得到的特征 $F_0$ 将作为主干网络的初始输入;
对于 $I_"HR"$，提取得到的特征 $F_"guide"$ 将作为视觉引导信号，被送入后续的视觉感知路由模块中，用于指引特征的分流和MoE中专家的选择。

编码器旨在逐步降低特征的空间分辨率并增加通道数，以获取更大的感受野。它包含 4 个层级，每个层级由若干个 Transformer Block 堆叠而成。这些 Block 采用了 Restormer 的核心组件——多头转置注意力机制（MDTA）和门控前馈网络（GDFN），以在特征维度上高效聚合上下文信息。与传统共享参数的 Restormer 不同，为了解决一体化训练中的任务干扰问题，我们在编码器的每个层级中嵌入了视觉感知路由模块（Visual-Aware Routing Module, VARM）。

在网络结构中，VARM 被放置在每个层级的 Transformer Block 之后。该模块同时接收当前层级输出的主干特征 $F_l^"enc"$ 与经过下采样的引导特征 $F_"guide"^l$，其中 $l$ 表示层级索引。$F_"guide"$ 中蕴含的丰富纹理、边缘和结构信息在此充当"视觉罗盘"的角色，VARM 通过融合主干特征与引导特征的统计信息，动态地计算像素级的门控权重，从而决定每个空间位置的特征应被分配至哪一组专家网络进行处理。通过这种视觉感知驱动的动态路由，网络能够依据输入图像的底层视觉特性，将特征动态分流至最适合当前纹理分布的专家网络（Experts）中。这种机制在编码阶段实现了物理路径的解耦，使得不同任务能够激活不同的参数子集。例如，全色锐化任务所涉及的高频空间细节特征会被路由至擅长处理精细纹理的专家分支，而深度图超分任务中的平滑梯度特征则会被导向另一组专家。由此，不同任务的梯度更新在参数空间中被有效隔离，从根本上缓解了梯度冲突与负迁移问题。在编码器的各层级之间，空间下采样操作通过 Pixel-Unshuffle 实现。该操作将空间维度为 $H times W$ 的特征图重组为 $H/2 times W/2$ 的特征图，同时通道数增加为原来的 4 倍，随后通过一个 $1 times 1$ 卷积层将通道数调整至目标维度。相较于传统的步幅卷积（Strided Convolution）或池化（Pooling）操作，Pixel-Unshuffle 在减少空间维度的同时能够完整保留通道信息，有效避免了下采样过程中的信息丢失。

解码器由 4 个与编码器对称的层级组成，负责逐步恢复图像的空间分辨率。每个解码器层级包含对应数量的 Transformer Block，用于从深层编码特征中重建高频细节与精细纹理。为了弥补逐层下采样过程中不可避免的空间信息损失，网络引入了跳跃连接（Skip Connections），将编码器各层级的输出特征与解码器对应层级的输入特征在通道维度上进行拼接（Concatenation），并通过一个 $1 times 1$ 卷积层将拼接后的通道数压缩回当前层级的标准维度。跳跃连接使得解码器在重建过程中能够直接访问编码器提取的多尺度浅层特征，从而保留更丰富的空间结构信息，提升重建图像的质量。需要说明的是，基于前期的实验观察（详见本章消融实验部分），不同任务间的特征差异主要体现在特征提取与理解阶段，即编码器部分。在解码器阶段，来自不同任务的特征经过编码器的动态路由已经被充分解耦和提纯，此时对它们进行共享参数的重建处理并不会引发显著的干扰。因此，为了保持模型的计算效率，我们在解码器阶段并未引入路由模块，而是沿用了标准的静态 Transformer Block 结构。解码器各层级之间的特征上采样通过 Pixel-Shuffle 操作实现，该操作将通道维度上的冗余信息重组到空间维度，逐步将特征图放大至目标分辨率。

经过解码器处理后，网络得到与输入 $I_"LR"$ 具有相同空间分辨率（即 $"sH" times "sW"$）的深层特征表示。该特征通过一个 $3 times 3$ 卷积层映射回原始图像的通道空间，得到残差图像 $I_"res" in RR^("sH" times "sW" times C_"in")$。最终的超分辨率重建结果 $I_"SR"$ 通过残差学习策略获得，即将残差图像与经双线性插值上采样至目标分辨率的输入图像相加：

$ I_"SR" = I_"res" + "Upsample"(I_"LR") $

其中 $"Upsample"(dot)$ 表示双线性插值上采样操作。这种残差学习范式使得网络只需学习低分辨率输入与高分辨率目标之间的高频差异部分，而非从零开始重建完整图像，显著降低了学习难度并加速了模型的收敛过程。


=== 基于视觉感知的动态路由模块 <VPNet-VPRM>

视觉感知路由模块（Visual-Perception Routing Module, VPRM）是 VP-Net 实现一体化多任务处理的核心组件。该模块的设计目标是利用高分辨率引导图像中蕴含的纹理、边缘与结构信息作为"视觉罗盘"，为主干特征中的每个空间位置动态选择最合适的专家网络进行处理，从而在参数空间中实现不同任务特征的物理隔离。VPRM 的结构如 @fig:VPRM-Arch 所示。

#figure(
  caption: [视觉感知路由模块（VPRM）结构示意图],
)[
#image("../images/实验图片/第三章/VPRM.png", width: 90%)
] <VPRM-Arch>

VPRM 采用稀疏门控混合专家（Sparsely-Gated Mixture-of-Experts）架构，其内部包含三个关键组成部分：视觉感知门控网络（Visual-Perception Gating Network）、专家网络组（Expert Networks）以及稀疏分发与加权聚合机制（Sparse Dispatch & Weighted Aggregation）。

对于编码器第 $l$ 层级，VPRM 接收两个输入：当前层级的主干特征 $F_L in RR^(B times C_l times H_l times W_l)$ 以及经过同步下采样的引导特征 $F_G in RR^(B times C_l times H_l times W_l)$。视觉感知门控网络首先将两者在通道维度上进行拼接，得到融合特征：

$ F_"fuse" = "Conv"_(1 times 1) (["Concat"(F_G, F_L)]) in RR^(B times 2C_l times H_l times W_l) $

其中 $"Conv"_(1 times 1)(dot)$ 表示 $1 times 1$ 逐点卷积操作。该卷积层的作用在于对拼接后的引导特征与主干特征进行跨模态信息融合，使门控网络能够同时感知引导图像的高频结构信息与目标图像的当前特征状态。随后，融合特征 $F_"fuse"$ 被重塑为像素级的特征向量序列 $bold(f)_"fuse" in RR^(N times 2C_l)$（其中 $N = B times H_l times W_l$ 为总的空间像素数量），并通过一个可学习的线性投影层 $bold(W)_g in RR^(2C_l times M)$（其中 $M$ 为专家总数）计算每个像素位置对各专家的路由分数：

$ bold(s) = bold(f)_"fuse" bold(W)_g in RR^(N times M) $

在训练阶段，为了增强路由决策的探索性并防止门控网络过早坍缩至固定的专家分配模式，VPRM 引入了带噪声的 Top-$k$ 门控机制（Noisy Top-$k$ Gating）。具体而言，通过另一组可学习参数 $bold(W)_"noise" in RR^(2C_l times M)$ 生成依赖于输入的噪声标准差，并向路由分数中注入可控的高斯噪声：

$ bold(sigma) = "Softplus"(bold(f)_"fuse" bold(W)_"noise") + epsilon $

$ tilde(bold(s)) = bold(s) + bold(xi) dot.circle bold(sigma), quad bold(xi) tilde cal(N)(0, bold(I)) $

其中 $epsilon$ 为一个极小的正常数以保证数值稳定性，$dot.circle$ 表示逐元素乘法。基于带噪声的路由分数 $tilde(bold(s))$，门控网络为每个像素选取得分最高的 $k$ 个专家（在本章实现中 $k = 2$），并对这 $k$ 个专家的分数进行 Softmax 归一化以获得最终的门控权重：

$ G(bold(f)_"fuse")_i = cases("Softmax"(tilde(bold(s))_i) & "if" i in "TopK"(tilde(bold(s))), 0 & "otherwise") $

其中 $"TopK"(dot)$ 返回分数最高的 $k$ 个专家的索引集合。未被选中的专家对应的门控权重为零，由此实现了稀疏激活——每个像素仅被路由至 $k$ 个专家，而非全部 $M$ 个专家，从而在引入多专家多样性的同时有效控制了计算开销。本章中，我们通过实验验证了 $k=2, M=4$ 的设置在性能与效率之间达到了较好的平衡，既能充分利用多专家的优势，又不会引入过多的计算负担。

专家网络组由 $M$ 个结构相同但参数独立的多层感知机（MLP）组成。每个专家 $E_i$（$i = 1, 2, dots, M$）包含两层全连接层，中间以 GELU 激活函数连接：

$ E_i (bold(x)) = bold(W)_i^2 dot "GELU"(bold(W)_i^1 bold(x) + bold(b)_i^1) + bold(b)_i^2 $

其中 $bold(W)_i^1 in RR^(C_l times d_h)$、$bold(W)_i^2 in RR^(d_h times C_l)$ 为第 $i$ 个专家的权重矩阵，$d_h$ 为隐藏层维度（通过膨胀因子 $r$ 控制，即 $d_h = r dot C_l$）。每个专家拥有独立的参数空间，能够学习特定的特征变换模式，例如某些专家可能专注于高频纹理的增强，而另一些专家则擅长处理低频平滑区域。

在稀疏分发阶段，VPRM 根据门控权重将主干特征 $F_L$ 中的像素级特征向量分发至对应的专家网络。仅门控权重非零的像素-专家对会产生实际的计算，未被选中的专家不参与当前像素的处理。各专家独立地对分配给自身的特征子集进行变换后，其输出通过门控权重进行加权求和，得到最终的路由输出：

$ hat(F)_L = sum_(i=1)^M G(bold(f)_"fuse")_i dot E_i (F_L) $

最终，VPRM 的输出通过残差连接与原始主干特征相加，确保信息流动的畅通性并降低训练难度：

$ F_L^"out" = hat(F)_L + F_L $

通过上述视觉感知驱动的动态路由机制，VPRM 能够根据引导图像所提供的视觉先验信息，在像素级别对特征进行自适应的专家分配。不同模态、不同纹理特性的输入数据将被自动路由至不同的专家子集，实现了特征提取路径的物理解耦，从根本上缓解了一体化训练中的任务干扰与梯度冲突问题。

=== 损失函数 <VPNet-Loss>

VP-Net 的总体训练损失由两部分组成：重建损失 $cal(L)_1$ 和负载均衡正则化损失 $cal(L)_"Balance"$，其表达式为：

$ cal(L) = cal(L)_1 + gamma cal(L)_"Balance" $

其中 $cal(L)_1$ 为像素级的 $L_1$ 重建损失，用于度量网络输出的超分辨率重建图像 $I_"SR"$ 与对应的高分辨率真实标签 $I_"GT"$ 之间的差异：

$ cal(L)_1 = || I_"SR" - I_"GT" ||_1 $

$L_1$ 损失相较于 $L_2$ 损失对异常值更为鲁棒，能够在保持整体重建精度的同时更好地恢复图像的高频纹理细节，已被广泛应用于图像超分辨率任务中。

$cal(L)_"Balance"$ 是专门为混合专家（MoE）架构设计的负载均衡正则化项，其目的在于防止门控网络在训练过程中出现"专家坍缩"现象——即大量像素被持续分配至少数几个专家，而其余专家长期处于闲置状态，导致模型的参数容量未能被充分利用。该损失由重要性损失（Importance Loss）和负载损失（Load Loss）两部分组成，分别从权重分配和选择频率两个角度约束各专家的使用趋于均匀：

$ cal(L)_"Balance" = "CV"^2 (sum_(n=1)^N G(bold(f)_"fuse"^n)) + "CV"^2 ("Load"(bold(G))) $

其中 $"CV"^2(dot)$ 表示变异系数的平方，定义为样本方差除以样本均值的平方，$sum_(n=1)^N G(bold(f)_"fuse"^n)$ 统计每个专家在当前批次中所获得的门控权重之和（即重要性），$"Load"(bold(G))$ 统计每个专家在当前批次中被选中的次数。当所有专家被等概率地选择且获得相同的累积权重时，两项变异系数均趋近于零，损失达到最小值。在实际实现中，编码器各层级（前三个层级）的 VPRM 模块各自计算负载均衡损失，并将其累加作为总的 $cal(L)_"Balance"$。超参数 $gamma$ 作为平衡权重，控制负载均衡正则化的强度，在本章实验中设定为 $gamma = 0.01$，以确保负载均衡约束不会过度干扰主重建任务的优化方向。

== 实验设置

为验证本章所提出的 VP-Net 在一体化 GISR 任务中的有效性，我们在三个具有代表性的 GISR 子任务上进行了全面的实验评估，分别为全色锐化（Pansharpening）、深度图超分辨率（Depth Image SR）以及磁共振图像超分辨率（MR Image SR）。本节将依次介绍实验所用的数据集、评测指标以及训练实现细节。

=== 数据集

本章实验涵盖了三类不同模态的 GISR 子任务，每类任务均选取了领域内广泛使用的公开基准数据集。@fig:dataset-visual 展示了三种任务的输入与输出示例，包括低分辨率输入、高分辨率引导图像及高分辨率真值。

#figure(
  caption: [三种 GISR 子任务的数据集示例。每一行展示一个任务（从上至下依次为：全色锐化、磁共振图像超分、深度图超分），包括低分辨率输入、高分辨率引导图像及高分辨率真值。],
)[
#image("../images/实验图片/第三章/dataset.png", width: 95%)
] <dataset-visual>

对于全色锐化任务，我们在三个不同卫星传感器的数据集上进行实验，分别为 QuickBird（QB）、WorldView-4（WV4）和 GaoFen-1（GF1）。这三个数据集在光谱响应特性、空间分辨率以及成像条件上各具特点，能够全面评估方法在不同遥感场景下的泛化能力。在数据预处理阶段，我们将原始图像对裁剪为小尺寸的训练样本，每组训练样本包含一幅 $128 times 128 times 1$ 的高分辨率全色（PAN）图像作为引导图像、一幅 $32 times 32 times 4$ 的低分辨率多光谱（LRMS）图像作为待超分的目标图像，以及一幅 $128 times 128 times 4$ 的高分辨率多光谱（HRMS）图像作为训练的真实标签（Ground Truth）。超分辨率倍率为 $4 times$。


对于深度图超分辨率任务，我们选取了广泛认可的 NYU v2 基准数据集。该数据集包含 1449 对 RGB-D 图像，其中 RGB 图像作为高分辨率引导图像，深度图作为待超分的低分辨率目标图像。按照领域内通用的实验设置，我们使用其中 1000 对图像用于训练，剩余 449 对图像用于测试。为了全面评估方法在不同降质程度下的重建能力，我们分别设置了 $4 times$、$8 times$ 和 $16 times$ 三种超分辨率倍率。低分辨率深度图通过对原始深度图进行双三次下采样获得。

对于磁共振图像超分辨率任务，我们在 BrainTS 数据集上进行评估。该数据集包含 285 个多对比度磁共振体数据（Multi-contrast MR Volumes），涵盖了 T1、T1ce、T2 和 FLAIR 四种对比度模态。在数据准备过程中，我们从每个体数据中选取中间 100 个切片，并剔除内容信息不足的切片，最终获得 20480 个切片用于训练，2320 个切片用于测试。引导图像为同一受试者的另一对比度磁共振切片，超分辨率倍率分别设置为 $2 times$、$4 times$ 和 $8 times$。

=== 评测指标

针对不同任务的特点，我们采用了与之相适配的图像质量评价（Image Quality Assessment, IQA）指标。

在全色锐化任务中，我们采用三种互补的评价指标：峰值信噪比（Peak Signal-to-Noise Ratio, PSNR）用于衡量重建图像与真实标签之间的整体像素级保真度，其值越高表示重建质量越好；光谱角度映射（Spectral Angle Mapper, SAM）从光谱一致性的角度评估重建图像是否保持了原始多光谱图像的光谱特征，其值越低表示光谱失真越小；综合无量纲全局误差（Erreur Relative Globale Adimensionnelle de Synthèse, ERGAS）则从全局角度综合评价空间与光谱质量，其值越低表示整体重建质量越高。

在深度图超分辨率任务中，我们采用均方根误差（Root Mean Square Error, RMSE）作为主要评价指标。RMSE 直接度量重建深度图与真实深度图之间的像素级偏差，能够反映深度值估计的精确程度，其值越低表示重建精度越高。

在磁共振图像超分辨率任务中，我们采用 PSNR 和结构相似性指数（Structural Similarity Index Measure, SSIM）两种指标对重建质量进行评估。PSNR 衡量像素级的重建精度，SSIM 则从亮度、对比度和结构三个维度综合评价重建图像与真实标签之间的感知相似性。两项指标的值越高，均表示重建质量越好。

=== 实验细节

所有实验均基于 PyTorch 深度学习框架实现，在单块 NVIDIA RTX 3090 GPU 上进行训练和测试。模型训练采用 Adam 优化器，批次大小（Batch Size）设置为 4，初始学习率设定为 $4 times 10^(-4)$，并采用余弦退火（Cosine Annealing）学习率调度策略在训练过程中逐步衰减学习率。

在骨干网络的架构配置方面，编码器-解码器的四个层级分别包含 $L_1 = 3$、$L_2 = 4$、$L_3 = 4$、$L_4 = 5$ 个 Transformer Block，体现了由浅到深逐步增加模型容量的设计理念。基础通道维度 $C$ 设定为 42，各层级的注意力头数分别为 1、2、4、8，门控前馈网络的通道膨胀因子设为 2.66。在 VPRM 模块中，专家总数 $M = 4$，每个像素激活的专家数 $k = 2$。负载均衡损失的权重系数 $gamma = 0.01$。

在一体化训练设置中，模型在三个任务的所有数据集上进行联合训练。由于不同任务的数据集规模存在差异，我们将每个训练轮次（Epoch）的长度对齐至最小数据集（深度图超分辨率任务的 1000 对训练样本）。在每个轮次结束后，所有数据集均进行重新随机打乱（Reshuffle），以确保训练过程中的样本多样性。模型总共训练 500 个轮次。在单任务训练设置（One-by-One）中，模型分别在各任务的数据集上独立训练，每个任务同样训练 500 个轮次，以便与一体化设置进行公平对比。

== 实验结果

为了验证本章提出的面向一体化任务的视觉感知与动态路由GISR方法（VP-Net）的有效性，我们在全色锐化、磁共振图像超分及深度图超分三个典型任务上进行了广泛的实验。实验主要包含两个部分：首先通过对比实验，验证VP-Net在多任务混合训练设置下相较于基准模型及通用模型的性能优势；其次通过消融实验，深入探究视觉感知路由模块（VARM）的核心贡献及架构设计选择；最后通过可视化分析，直观展示动态路由机制在特征空间中的工作机理。


=== 对比实验

为了验证本章方法在多任务联合训练模式下的有效性，我们将 VP-Net 与近年来提出的主流一体化图像复原网络进行了全面对比，对比方法包括 Gridformer、Transweather、CAPTNet、AdaIR 以及 PromptIR。

在进行对比实验时，我们需要克服一个技术障碍：现有的通用一体化图像复原方法（如 Transweather、PromptIR）通常仅针对 RGB 图像设计，默认输入通道为 3。然而，GISR 任务涉及多模态数据，且通道数各异（例如，磁共振图像超分为 1通道 T1 + 1通道 T2 = 2通道；深度图超分为 1通道 Depth + 3通道 RGB = 4通道；全色锐化为 4通道 LRMS + 1通道 PAN = 5通道）。为了公平地将这些基准方法应用于 GISR 任务，我们参考了 VP-Net 的输入处理方式，对基准模型的输入层进行了轻量级适配：针对每个特定的输入通道配置，我们分别初始化了独立的浅层特征提取层（Patch Embedding Layer），将不同维度的原始输入映射到统一的特征维度 $C$。这种处理方式在不改变基准模型核心架构与参数量级的前提下，使其能够兼容多模态、多维度的 GISR 数据输入。

@tab:VPNet_all-in-one_pansharpening 展示了全色锐化任务在 WV4、QB 和 GF1 三个卫星数据集上的定量评估结果。可以看出，VP-Net 在绝大多数指标上均取得了最优（Bold）的成绩。特别是与同样基于 Transformer 架构的 PromptIR 相比，VP-Net 在保持参数量相当的情况下，PSNR 指标得到进一步提升，这得益于视觉感知路由对不同光谱特征的精细化处理。

@tab:VPNet_all-in-one_mri 和 @tab:VPNet_all-in-one_depth 分别列出了磁共振图像超分辨率和深度图超分辨率任务的对比数据。在 MR 图像超分中，VP-Net 在 2×、4× 和 8× 三个尺度上均表现出一致的性能优势。在深度图超分任务中，VP-Net 的 RMSE 误差始终低于或持平于最强基准 PromptIR，尤其是在高倍率（16×）重建中，能够更好地重构深度结构。实验结果表明，通过动态路由实现特征的物理解耦，能够有效避免不同模态任务之间的负迁移现象，从而打破整体系统的性能瓶颈。

#include "../tables/03/all-in-one/Pansharpening.typ"

#include "../tables/03/all-in-one/MRI.typ"

#include "../tables/03/all-in-one/Depth.typ"


=== 消融实验

为了验证 VP-Net 中核心设计选择的合理性，我们进行了一系列消融实验。实验主要关注两个方面：一是视觉感知路由模块（VPRM）本身的有效性，二是 VPRM 在网络架构中的最佳部署位置。

#heading(level: 4, numbering: none)[VPRM有效性消融分析]

为了验证 VPRM 在缓解多任务干扰方面的贡献，我们构建了一个基准模型（w/o VPRM），即移除 VP-Net 中所有的 VPRM 模块，退化为标准的共享参数 Restormer 架构，并在相同的数据设置下进行多任务联合训练。@tab:VPNet_ablation_VPRM 展示了基准模型与完整 VP-Net 的性能对比。

由表可知，相较于基准模型，引入 VPRM 后的 VP-Net 在所有任务的各项指标上均取得了显著提升。例如，在全色锐化任务的 GF1 数据集上，PSNR 提升了近 1 dB；在深度图超分任务中，RMSE 误差也得到明显降低。这一结果充分表明，简单的参数共享策略在处理差异巨大的异构模态时存在局限性，而 VPRM 通过基于视觉特征的动态路由机制，成功实现了任务特征的物理解耦，有效缓解了负迁移现象，从而大幅提升了一体化模型的重建质量。

#include "../tables/03/ablation/VPRM.typ"

#heading(level: 4, numbering: none)[VPRM位置消融分析]

VPRM 应当部署在网络的什么位置才能最大化其效能？为了回答这个问题，我们对比了三种不同的部署策略：(1) 仅在编码器中部署（Encoder, 即 VP-Net 最终方案）；(2) 仅在解码器中部署（Decoder）；(3) 同时在编码器和解码器中部署（Both）。实验结果如 @tab:VPNet_ablation_position 所示。

首先，对比 Encoder 和 Decoder 的结果可以发现，将路由模块置于编码阶段的性能明显优于解码阶段。这印证了我们的假设：不同任务间的模态差异（Domain Gap）主要存在于特征提取与理解阶段。在编码器中尽早进行特征分流与解耦，能够避免特征在深层发生混淆，为后续重建打下良好基础。

其次，对比“Encoder”与“Both”方案，可以观察到“Both”设置虽然在全色锐化和磁共振超分任务上取得了极其微弱的性能优势（例如 Pan WV4 上 PSNR 仅高出 0.02 dB），但在深度图超分任务上，其性能甚至略逊于仅编码器设置。更关键的是，双端部署带来了巨大的计算代价。引入更多的专家网络不仅显著增加了模型的参数量，还大幅提高了推理延迟。此外，过多的动态路由决策节点显著增加了训练的复杂性，导致模型优化难度增大，极难收敛。综合考虑性能、效率与训练稳定性，我们认为仅在编码器中部署 VPRM 是最优的选择，它在保持高效推理的同时，实现了与更复杂模型相当的性能表现。

#include "../tables/03/ablation/position.typ"

=== 动态路由机制的可视化分析

为了直观地揭示 VP-Net 如何缓解多任务干扰，我们可视化了不同任务在编码器各层级（L1-L4）对各个专家（E0-E3）的平均激活率。激活热力图如 @fig:VPRM-moe_activation_heatmap 所示，其中颜色的深浅代表每个专家被激活的频率。

从图中可以观察到明显的专家选择偏好差异，这证实了 VP-Net 成功实现了基于任务特性的特征解耦：

1.  **浅层（L1）的显著分化**：在网络的浅层，专家选择的差异最为剧烈。例如，MRI 任务极度依赖专家 E1（深蓝色高亮），而对其他专家（特别是 E2 和 E3）的激活率极低。相反，Pan 任务则表现出对专家 E2 和 E3 的偏好，对 E0 和 E1 的依赖相对较少。这表明网络在特征提取的早期阶段就已经开始区分不同模态的视觉特征，将光谱信息丰富的全色影像与解剖结构复杂的磁共振影像路由至完全不同的处理路径，从而从源头上避免了特征混淆。

2.  **深层（L4）的趋同性**：随着网络层级的加深，不同任务的专家激活分布逐渐趋于均匀（颜色差异变浅）。这说明在深层语义空间中，尽管输入模态不同，网络提取的高层抽象特征开始表现出一定的共性（如对物体轮廓或纹理复原的通用需求）。此时，各任务开始共享更多的专家参数，实现了知识的迁移与互补。

3.  **任务间的独特性与重叠**：Depth 任务与 Pan 任务在某些专家（如 L1_E1）上的激活模式存在重叠，但也保留了自身的独特性。这种“部分共享、部分独立”的路由机制正是 MoE 架构的优势所在——它既不像硬性参数隔离（Hard Parameter Sharing）那样完全阻断任务间的联系，也不像全参数共享那样导致剧烈的干扰，而是通过动态门控实现了一种“软性”的平衡，确保每个任务都能找到最优的参数组合。

综上所述，可视化分析证实了 VPRM 能够根据输入模态的底层视觉特征，自动学习并规划出差异化的特征处理路径。这种动态分流策略不仅在理论上解释了 VP-Net 性能提升的原因，也在实践中展示了其处理多模态冲突的强大能力。

#figure(
  caption: [动态路由机制激活热力图],
)[
#image("../images/实验图片/第三章/moe_activation_heatmap.png", width: 90%)
] <VPRM-moe_activation_heatmap>

== 本章小结

本章针对多模态引导图像超分辨率任务中存在的“负迁移”与参数干扰问题，提出了一种基于视觉感知与动态路由的一体化网络模型（VP-Net）。该方法通过引入视觉感知路由模块（VPRM），利用引导图像的纹理与结构信息作为“视觉罗盘”，实现了特征处理路径的动态规划与物理隔离。

首先，本章详细阐述了 VP-Net 的整体架构设计，重点介绍了 VPRM 模块如何通过稀疏门控机制在像素级别分配专家网络，从而解决不同模态数据在特征空间中的分布冲突。其次，通过在全色锐化、磁共振图像超分和深度图超分三个典型任务上的广泛实验，验证了 VP-Net 在一体化训练设置下相较于现有 SOTA 方法的性能优势。特别是在处理异构模态数据时，VP-Net 展现出了优异的鲁棒性与泛化能力。最后，通过消融实验与可视化分析，深入揭示了动态路由机制在特征解耦与知识共享中的工作机理，证明了“仅编码器部署”策略在性能与效率之间的最佳平衡。本章的研究为构建通用、高效的多模态图像复原系统提供了新的视角与解决方案。
